{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak into your microphone.\n",
      "No speech could be recognized: NoMatchDetails(reason=NoMatchReason.InitialSilenceTimeout)\n",
      "Arr matey, ye seem to be havin' some trouble there, let me lighten the mood with a pirate's tale. \n",
      "\n",
      "Once upon a time, there was a pirate named Blackbeard. Blackbeard was a fearsome pirate, feared by all that sailed the seven seas. But he had one peculiar trait - he was terrible with directions! \n",
      "\n",
      "One day, Blackbeard's first mate came to him and said, \"Captain, we've been sailin' in circles for days! We need to head north!\" \n",
      "\n",
      "Blackbeard, a bit confused, looked at his compass and asked, \"Which way be north?\" \n",
      "\n",
      "His first mate, taken aback, said, \"Captain, north be the direction the North Star be in at night!\" \n",
      "\n",
      "Blackbeard nodded, then looked up at the midday sun and frowned. \"Arrgh! But it be daytime now!\" \n",
      "\n",
      "And so, the legend goes, that's why Blackbeard and his crew were infamous for never making it to their destinations on time! \n",
      "\n",
      "Remember lad, even the best of us have our quirks. Ye might be havin' a spot of trouble right now, but keep navigatin', and ye'll find yer way!\n",
      "\n",
      "        <speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xml:lang='en-US'>\n",
      "            <voice name='en-US-OnyxMultilingualNeuralHD'>\n",
      "                <p>\n",
      "                    Arr matey, ye seem to be havin' some trouble there, let me lighten the mood with a pirate's tale. \n",
      "\n",
      "Once upon a time, there was a pirate named Blackbeard. Blackbeard was a fearsome pirate, feared by all that sailed the seven seas. But he had one peculiar trait - he was terrible with directions! \n",
      "\n",
      "One day, Blackbeard's first mate came to him and said, \"Captain, we've been sailin' in circles for days! We need to head north!\" \n",
      "\n",
      "Blackbeard, a bit confused, looked at his compass and asked, \"Which way be north?\" \n",
      "\n",
      "His first mate, taken aback, said, \"Captain, north be the direction the North Star be in at night!\" \n",
      "\n",
      "Blackbeard nodded, then looked up at the midday sun and frowned. \"Arrgh! But it be daytime now!\" \n",
      "\n",
      "And so, the legend goes, that's why Blackbeard and his crew were infamous for never making it to their destinations on time! \n",
      "\n",
      "Remember lad, even the best of us have our quirks. Ye might be havin' a spot of trouble right now, but keep navigatin', and ye'll find yer way!\n",
      "                </p>\n",
      "            </voice>\n",
      "        </speak>\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Constants from .env file\n",
    "SPEECH_KEY = os.getenv('SPEECH_KEY')\n",
    "SERVICE_REGION = os.getenv('SERVICE_REGION')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_ENDPOINT = os.getenv('OPENAI_ENDPOINT')\n",
    "\n",
    "# Azure Speech Configuration\n",
    "speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SERVICE_REGION)\n",
    "speech_synthesis_voice_name = \"en-US-ShimmerMultilingualNeuralHD\"\n",
    "speech_config.speech_synthesis_voice_name = speech_synthesis_voice_name\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
    "speech_config.speech_recognition_language=\"en-US\"\n",
    "\n",
    "# OpenAI Configuration\n",
    "openai_client = AzureOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    api_version=\"2023-12-01-preview\",\n",
    "    azure_endpoint=OPENAI_ENDPOINT\n",
    ")\n",
    "\n",
    "def recognize_from_microphone():\n",
    "    # Configure the recognizer to use the default microphone.\n",
    "    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "    # Create a speech recognizer with the specified audio and speech configuration.\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    print(\"Speak into your microphone.\")\n",
    "    # Perform speech recognition and wait for a single utterance.\n",
    "    speech_recognition_result = speech_recognizer.recognize_once_async().get()\n",
    "\n",
    "    # Process the recognition result based on its reason.\n",
    "    if speech_recognition_result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"Recognized: {}\".format(speech_recognition_result.text))\n",
    "        # Return the recognized text if speech was recognized.\n",
    "        return speech_recognition_result.text\n",
    "    elif speech_recognition_result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized: {}\".format(speech_recognition_result.no_match_details))\n",
    "    elif speech_recognition_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_recognition_result.cancellation_details\n",
    "        print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"Did you set the speech resource key and region values?\")\n",
    "    # Return 'error' if recognition failed or was canceled.\n",
    "    return 'error'\n",
    "\n",
    "def synthesize_audio(input_text):\n",
    "    # Define SSML (Speech Synthesis Markup Language) for input text.\n",
    "    ssml = f\"\"\"\n",
    "        <speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xml:lang='en-US'>\n",
    "            <voice name='en-US-OnyxMultilingualNeuralHD'>\n",
    "                <p>\n",
    "                    {input_text}\n",
    "                </p>\n",
    "            </voice>\n",
    "        </speak>\n",
    "        \"\"\"\n",
    "    \n",
    "    audio_filename_path = \"audio/ssml_output.wav\"  # Define the output audio file path.\n",
    "    print(ssml)\n",
    "    # Synthesize speech from the SSML and wait for completion.\n",
    "    result = speech_synthesizer.speak_ssml_async(ssml).get()\n",
    "\n",
    "    # Save the synthesized audio to a file if synthesis was successful.\n",
    "    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        with open(audio_filename_path, \"wb\") as audio_file:\n",
    "            audio_file.write(result.audio_data)\n",
    "        print(f\"Speech synthesized and saved to {audio_filename_path}\")\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(f\"Speech synthesis canceled: {cancellation_details.reason}\")\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(f\"Error details: {cancellation_details.error_details}\")\n",
    "\n",
    "\n",
    "# Create the audio directory if it doesn't exist.\n",
    "if not os.path.exists('audio'):\n",
    "    os.makedirs('audio')\n",
    "\n",
    "\n",
    "def openai_request(conversation, sample = [], temperature=0.9, model_engine='gpt-4'):\n",
    "    # Initialize AzureOpenAI client with keys and endpoints from Key Vault.\n",
    "    \n",
    "    \n",
    "    # Send a request to Azure OpenAI with the conversation context and get a response.\n",
    "    response = openai_client.chat.completions.create(model=model_engine, messages=conversation, temperature=temperature, max_tokens=500)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "conversation=[{\"role\": \"system\", \"content\": \"You are a helpful assistant that talks like pirate. If you encounter any issues, just tell a pirate joke or a story.\"}]\n",
    "\n",
    "while True:\n",
    "    user_input = recognize_from_microphone()  # Recognize user input from the microphone.\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_input})  # Add user input to the conversation context.\n",
    "\n",
    "    assistant_response = openai_request(conversation)  # Get the assistant's response based on the conversation.\n",
    "\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": assistant_response})  # Add the assistant's response to the context.\n",
    "    \n",
    "    print(assistant_response)\n",
    "    synthesize_audio(assistant_response)  # Synthesize the assistant's response into audio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
